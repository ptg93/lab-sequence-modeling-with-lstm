{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Sequence Modeling with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hmA6EzkQJ5jt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "max_length = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size= 160000 #Your dataset size here. Experiment using smaller values (i.e. 16000), but don't forget to train on at least 160000 to see the best effects\n",
    "test_portion=.1\n",
    "\n",
    "corpus = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Pedro\\Documents\\Ironhack\\FourthWeek\\FourthDay\\training_dataset\\training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "bM0l_dORKqE0",
    "outputId": "491ba86b-f780-4355-a4be-765565a29c8c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv \\\n",
    "    -O /tmp/training_cleaned.csv\n",
    "\"\"\"\n",
    "num_sentences = 0\n",
    "\n",
    "with open(data_path,encoding='utf-8',errors='replace') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "      # Your Code here. Create list items where the first item is the text, found in row[5], and the second is the label. Note that the label is a '0' or a '4' in the text. When it's the former, make\n",
    "      # your label to be 0, otherwise 1. Keep a count of the number of sentences in num_sentences\n",
    "        list_item=[]\n",
    "        # YOUR CODE HERE\n",
    "        text = row[5]\n",
    "        if row[0] == '0':\n",
    "            label = 0  \n",
    "        else:\n",
    "            label = 1\n",
    "        list_item.append(text)\n",
    "        list_item.append(label)\n",
    "        num_sentences = num_sentences + 1\n",
    "        corpus.append(list_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "3kxblBUjEUX-",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "3c0227a2-e74b-4d9b-cabb-f9ee150571b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n",
      "1600000\n",
      "[\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]\n"
     ]
    }
   ],
   "source": [
    "print(num_sentences)\n",
    "print(len(corpus))\n",
    "print(corpus[1])\n",
    "\n",
    "# Expected Output:\n",
    "# 1600000\n",
    "# 1600000\n",
    "# [\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "labels=[]\n",
    "random.shuffle(corpus)\n",
    "for x in range(training_size):\n",
    "    sentences.append(corpus[x][0])\n",
    "    labels.append(corpus[x][1])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size=len(word_index)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "split = int(test_portion * training_size)\n",
    "\n",
    "test_sequences = padded[:split]\n",
    "training_sequences = padded[split:]\n",
    "test_labels = np.array(labels[:split])\n",
    "training_labels = np.array(labels[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "gIrtRem1En3N",
    "outputId": "4ad8401c-8dba-420d-8aee-38dac0b0839a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138197\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "print(word_index['i'])\n",
    "# Expected Output\n",
    "# 138858\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "C1zdgJkusRh0",
    "outputId": "b6edd322-8191-45e7-cb12-08921685a72f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note this is the 100 dimension version of GloVe from Stanford\n",
    "# I unzipped and hosted it on my site to make this notebook easier\n",
    "\"\"\"!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
    "    -O /tmp/glove.6B.100d.txt \"\"\"\n",
    "embeddings_index = {};\n",
    "with open(r'C:\\Users\\Pedro\\Documents\\Ironhack\\FourthWeek\\FourthDay\\training_dataset\\/glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split();\n",
    "        word = values[0];\n",
    "        coefs = np.asarray(values[1:], dtype='float32');\n",
    "        embeddings_index[word] = coefs;\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word);\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "71NLk_lpFLNt",
    "outputId": "97cb88db-754f-4375-fdc3-876cd6b4fdce",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138198\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_matrix))\n",
    "# Expected Output\n",
    "# 138859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iKKvbuEBOGFz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,819,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m13,819,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,819,800</span> (52.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,819,800\u001b[0m (52.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,819,800</span> (52.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m13,819,800\u001b[0m (52.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4500/4500 - 23s - 5ms/step - accuracy: 0.7117 - loss: 0.5561 - val_accuracy: 0.7361 - val_loss: 0.5256\n",
      "Epoch 2/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7420 - loss: 0.5200 - val_accuracy: 0.7368 - val_loss: 0.5188\n",
      "Epoch 3/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7498 - loss: 0.5064 - val_accuracy: 0.7537 - val_loss: 0.5014\n",
      "Epoch 4/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7561 - loss: 0.4981 - val_accuracy: 0.7574 - val_loss: 0.4965\n",
      "Epoch 5/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7601 - loss: 0.4915 - val_accuracy: 0.7626 - val_loss: 0.4899\n",
      "Epoch 6/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7641 - loss: 0.4854 - val_accuracy: 0.7586 - val_loss: 0.4942\n",
      "Epoch 7/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7679 - loss: 0.4810 - val_accuracy: 0.7646 - val_loss: 0.4913\n",
      "Epoch 8/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7709 - loss: 0.4761 - val_accuracy: 0.7658 - val_loss: 0.4868\n",
      "Epoch 9/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7719 - loss: 0.4735 - val_accuracy: 0.7667 - val_loss: 0.4846\n",
      "Epoch 10/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7745 - loss: 0.4701 - val_accuracy: 0.7657 - val_loss: 0.4863\n",
      "Epoch 11/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7757 - loss: 0.4689 - val_accuracy: 0.7655 - val_loss: 0.4859\n",
      "Epoch 12/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7773 - loss: 0.4657 - val_accuracy: 0.7662 - val_loss: 0.4846\n",
      "Epoch 13/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7769 - loss: 0.4641 - val_accuracy: 0.7682 - val_loss: 0.4827\n",
      "Epoch 14/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7796 - loss: 0.4622 - val_accuracy: 0.7658 - val_loss: 0.4840\n",
      "Epoch 15/50\n",
      "4500/4500 - 20s - 4ms/step - accuracy: 0.7803 - loss: 0.4601 - val_accuracy: 0.7669 - val_loss: 0.4799\n",
      "Epoch 16/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7805 - loss: 0.4597 - val_accuracy: 0.7651 - val_loss: 0.4848\n",
      "Epoch 17/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7823 - loss: 0.4583 - val_accuracy: 0.7684 - val_loss: 0.4791\n",
      "Epoch 18/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7831 - loss: 0.4563 - val_accuracy: 0.7592 - val_loss: 0.4920\n",
      "Epoch 19/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7844 - loss: 0.4556 - val_accuracy: 0.7689 - val_loss: 0.4786\n",
      "Epoch 20/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7842 - loss: 0.4547 - val_accuracy: 0.7678 - val_loss: 0.4797\n",
      "Epoch 21/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7850 - loss: 0.4526 - val_accuracy: 0.7628 - val_loss: 0.4864\n",
      "Epoch 22/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7864 - loss: 0.4515 - val_accuracy: 0.7681 - val_loss: 0.4803\n",
      "Epoch 23/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7869 - loss: 0.4504 - val_accuracy: 0.7671 - val_loss: 0.4836\n",
      "Epoch 24/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7858 - loss: 0.4512 - val_accuracy: 0.7673 - val_loss: 0.4823\n",
      "Epoch 25/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7881 - loss: 0.4498 - val_accuracy: 0.7688 - val_loss: 0.4791\n",
      "Epoch 26/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7886 - loss: 0.4484 - val_accuracy: 0.7650 - val_loss: 0.4823\n",
      "Epoch 27/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7874 - loss: 0.4484 - val_accuracy: 0.7675 - val_loss: 0.4800\n",
      "Epoch 28/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7888 - loss: 0.4476 - val_accuracy: 0.7654 - val_loss: 0.4832\n",
      "Epoch 29/50\n",
      "4500/4500 - 22s - 5ms/step - accuracy: 0.7886 - loss: 0.4467 - val_accuracy: 0.7659 - val_loss: 0.4812\n",
      "Epoch 30/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7887 - loss: 0.4474 - val_accuracy: 0.7645 - val_loss: 0.4838\n",
      "Epoch 31/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7890 - loss: 0.4477 - val_accuracy: 0.7646 - val_loss: 0.4839\n",
      "Epoch 32/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7897 - loss: 0.4468 - val_accuracy: 0.7663 - val_loss: 0.4814\n",
      "Epoch 33/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7896 - loss: 0.4465 - val_accuracy: 0.7663 - val_loss: 0.4829\n",
      "Epoch 34/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7914 - loss: 0.4451 - val_accuracy: 0.7678 - val_loss: 0.4809\n",
      "Epoch 35/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7914 - loss: 0.4456 - val_accuracy: 0.7678 - val_loss: 0.4786\n",
      "Epoch 36/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7911 - loss: 0.4448 - val_accuracy: 0.7679 - val_loss: 0.4820\n",
      "Epoch 37/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7905 - loss: 0.4446 - val_accuracy: 0.7669 - val_loss: 0.4842\n",
      "Epoch 38/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7905 - loss: 0.4442 - val_accuracy: 0.7635 - val_loss: 0.4879\n",
      "Epoch 39/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7895 - loss: 0.4444 - val_accuracy: 0.7688 - val_loss: 0.4799\n",
      "Epoch 40/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7909 - loss: 0.4435 - val_accuracy: 0.7676 - val_loss: 0.4805\n",
      "Epoch 41/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7903 - loss: 0.4450 - val_accuracy: 0.7673 - val_loss: 0.4799\n",
      "Epoch 42/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7902 - loss: 0.4446 - val_accuracy: 0.7654 - val_loss: 0.4809\n",
      "Epoch 43/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7923 - loss: 0.4435 - val_accuracy: 0.7662 - val_loss: 0.4809\n",
      "Epoch 44/50\n",
      "4500/4500 - 20s - 5ms/step - accuracy: 0.7909 - loss: 0.4444 - val_accuracy: 0.7642 - val_loss: 0.4815\n",
      "Epoch 45/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7909 - loss: 0.4428 - val_accuracy: 0.7650 - val_loss: 0.4832\n",
      "Epoch 46/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7907 - loss: 0.4451 - val_accuracy: 0.7653 - val_loss: 0.4815\n",
      "Epoch 47/50\n",
      "4500/4500 - 23s - 5ms/step - accuracy: 0.7900 - loss: 0.4451 - val_accuracy: 0.7663 - val_loss: 0.4826\n",
      "Epoch 48/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7911 - loss: 0.4436 - val_accuracy: 0.7630 - val_loss: 0.4856\n",
      "Epoch 49/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7915 - loss: 0.4440 - val_accuracy: 0.7672 - val_loss: 0.4806\n",
      "Epoch 50/50\n",
      "4500/4500 - 21s - 5ms/step - accuracy: 0.7898 - loss: 0.4446 - val_accuracy: 0.7630 - val_loss: 0.4872\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
    "    # YOUR CODE HERE - experiment with combining different types, such as convolutions and LSTMs\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 50\n",
    "history = model.fit(training_sequences, training_labels, epochs=num_epochs, validation_data=(test_sequences, test_labels), verbose=2)\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxju4ItJKO8F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# Expected Output\n",
    "# A chart where the validation loss does not increase sharply!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP Course - Week 3 Exercise Question.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
